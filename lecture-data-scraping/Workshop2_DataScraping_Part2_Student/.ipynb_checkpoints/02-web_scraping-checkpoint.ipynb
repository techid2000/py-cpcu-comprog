{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "00Z9Sz8gw7BY"
   },
   "source": [
    "# การทำ Web Scraping ด้วย Python\n",
    "\n",
    "#### --- แนะนำให้ใช้ Python 3 ---\n",
    "\n",
    "ก่อนอื่นเรามาทำการ Import Library ต่างๆ ที่จำเป็นต้องใช้กัน\n",
    "\n",
    "- `urllib` ใช้ในการเปิด url และโหลดหน้าเวบเพจ\n",
    "- `BeautifulSoup` ใช้ในการประมวลผลหน้า HTML \n",
    "- `sleep` ใช้ในการรอก่อนจะส่ง request หน้าเวบอันต่อไป\n",
    "- `copy` ใช้ในการ copy object "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "k3wgqT1Qw7Ba"
   },
   "outputs": [],
   "source": [
    "import urllib\n",
    "from bs4 import BeautifulSoup\n",
    "from time import sleep\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ทดลองดึงข้อมูล GDH จาก Wikipedia https://th.wikipedia.org/wiki/จีดีเอช_ห้าห้าเก้า\n",
    "\n",
    "<img src=\"https://i.bug-a-boo.tv/images/5d67f5de7caf08b85e02d97e2770b7ff/bugabooimage.jpg\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "โดยปกติแล้ว url จะต้องประกอบไปด้วยตัวอักษร ASCII เท่านั้น นั่นคือเป็นภาษาไทยไม่ได้! เราจะต้องทำการแปลง (หรือเรียกว่าการ quote string) ให้อยู่ในรูปแบบของ percent-encoded string เสียก่อนโดยใช้ฟังก์ชัน `urllib.quote()` (ปกติ browser ของเราจะทำการแปลงให้อัตโนมัติ ถ้าเราพิมพ์ภาษาไทยเข้าไป) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "p5pEKdxMw7Bg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "จีดีเอช_ห้าห้าเก้า => %E0%B8%88%E0%B8%B5%E0%B8%94%E0%B8%B5%E0%B9%80%E0%B8%AD%E0%B8%8A_%E0%B8%AB%E0%B9%89%E0%B8%B2%E0%B8%AB%E0%B9%89%E0%B8%B2%E0%B9%80%E0%B8%81%E0%B9%89%E0%B8%B2\n"
     ]
    }
   ],
   "source": [
    "page = 'จีดีเอช_ห้าห้าเก้า'\n",
    "print('จีดีเอช_ห้าห้าเก้า' + ' => ' + urllib.parse.quote(page)) # Use urllib.quote() for Python 2\n",
    "\n",
    "url = 'http://th.wikipedia.org/wiki/' + page"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sVB7UHgyw7Bk"
   },
   "source": [
    "เมื่อได้ url ที่พร้อมใช้งานแล้ว เราก็เรียก `urllib.urlopen()` ตามด้วยคำสั่ง `read()` เพื่ออ่านไฟล์ HTML ได้เลย \n",
    "\n",
    "ก่อนจะ `print()` เราอาจจะอยาก unquote string ก่อน เพื่อให้เราอ่าน url ใน link ต่างๆ บนหน้า HTML ที่เป็นภาษาไทยได้ง่ายขึ้น (ไม่เชื่อลอง `print()` แบบไม่ unquote ดู!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://th.wikipedia.org/wiki/จีดีเอช_ห้าห้าเก้า\n"
     ]
    }
   ],
   "source": [
    "# ----- TO DO 1 -----\n",
    "# แปลงข้อมูลในตัวแปร page โดยใช้ urllib.parse.quote() ให้อยู่ในรูปแบบ percent-encoded string \n",
    "# แล้วนำไปต่อท้าย 'http://th.wikipedia.org/wiki/' แล้วเก็บไว้ในตัวแปร url ตามเดิม\n",
    "\n",
    "url = urllib.parse.unquote(url)\n",
    "print(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "ybhH2sBTw7Bl"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'urllib' has no attribute 'urlopen'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-69e8f842cfff>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhtml\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0murllib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Use urllib.urlopen() for Python 2\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m# print(html)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# print(urllib.parse.unquote(str(html))) # Use urllib.unquote() for Python 2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'urllib' has no attribute 'urlopen'"
     ]
    }
   ],
   "source": [
    "html = urllib.request.urlopen(url).read() # Use urllib.urlopen() for Python 2\n",
    "# print(html)\n",
    "# print(urllib.parse.unquote(str(html))) # Use urllib.unquote() for Python 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KxovZKb3w7Bo"
   },
   "source": [
    "จากนั้นก็เรียกใช้งาน BeautifulSoup เพื่อทำการประมวลผล (parse) หน้า HTML ที่เราได้มา "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "Wom5UglIw7Bp"
   },
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "print(soup.prettify()[0:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## บริษัทในเครือปัจุบันของ GDH\n",
    "\n",
    "ในแบบฝึกหัดนี้เราจะทำการดึงข้อมูลบริษัทในเครือปัจจุบันและรายชื่อผู้กำกับภาพยนตร์ในสังกัด GDH จากหน้าวิกิพีเดียกัน \n",
    "\n",
    "<img src=\"source/current_branch.png\">\n",
    "\n",
    "จากภาพข้างต้น จะเห็นได้ว่าหัวข้อของตารางที่เขียนว่า **ปัจจุบัน** นั้น อยู่ภายใน Tag `<dt>` (description term) ทีนี้เรามาดูกันว่า เราจะสามารถดึง Element นั้นออกมาใช้งานได้อย่างไรบ้าง ค่อยๆลอง uncomment แต่ละวิธีแล้วลองรันดู"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# soup.find? \n",
    "\n",
    "print(\"1. soup.find('dt'):\")\n",
    "print(soup.find('dt'))\n",
    "\n",
    "#print(\"2. soup.dt:\") # shorthand \n",
    "#print(soup.dt) \n",
    "\n",
    "#print(\"3. soup.find_all('dt'):\")\n",
    "#print(soup.find_all('dt'))\n",
    "\n",
    "# print(\"4. soup('dt'):\") # shorthand \n",
    "# print(soup('dt')) \n",
    "\n",
    "#print(\"5. soup.find_all('dt')[0]:\")\n",
    "#print(soup.find_all('dt')[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "เนื่องจากหัวข้อปัจจุบันอยู่ใน Tag `<dt>` อันแรกของเพจนั้น เราสามารถเรียกใช้ element ได้ด้วยคำสั่ง `soup.find('dt')` หรือ `soup.dt`\n",
    "หรือหากเราอยากจะหา element `<dt>` ทั้งหมดก่อน แล้วค่อยเลือก element ที่เราต้องการ ก็ทำได้เช่นกัน แบบในตัวอย่างสุดท้าย"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MhVFfMqhw7Bs"
   },
   "source": [
    "## ผู้กำกับภาพยนตร์ในสังกัด GDH\n",
    "\n",
    "<img src=\"source/director.png\">\n",
    "\n",
    "ก่อนอื่นเราต้องมาหากันก่อนว่าข้อมูลผู้กำกับภาพยนตร์นั้นอยู่ส่วนไหนของเพจ ลอง Inspect เพจดูว่าเราจะสามารถใช้ Element ไหนเป็นจุดเริ่มต้นใน DOM Tree และค่อยๆไล่หาข้อมูลที่เราต้องการได้บ้าง"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "ทีนี้จาก `<span>ผู้กำกับในสังกัด</dt>` เราจะไปดึงรายชื่อผู้กำกับ ที่อยู่ใน `<ul>` (unordered list) ได้อย่างไร? จริงๆ แล้วสามารถทำได้หลากหลายวิธี ลองดูตัวอย่างสักสองวิธีดังต่อไปนี้ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(soup.find_all('b'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "dCHJSZQpw7B0"
   },
   "outputs": [],
   "source": [
    "director_list = soup.find_all('b')[3].parent.find_next_sibling()\n",
    "print(urllib.parse.unquote(str(director_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "8d7nO_ahw7B4"
   },
   "outputs": [],
   "source": [
    "director_list = soup.find('b', string='ผู้กำกับภาพยนตร์').find_next('ul')\n",
    "print(urllib.parse.unquote(str(director_list)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SURD38NDw7B8"
   },
   "source": [
    "เมื่อได้ `<ul>` ที่ต้องการมาเรียบร้อยแล้ว เราก็สามารถดึง text ที่อยู่ในแต่ละ `<li>` (list item) ในลิสต์นั้นได้เลย "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "eeWC6VeKw7B9"
   },
   "outputs": [],
   "source": [
    "for li in director_list('li'):\n",
    "    print(li.a.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DLLFQqtCw7CB"
   },
   "source": [
    "หลายคนอาจจะสังเกตเห็นว่ามีผู้กำกับบางคนยังไม่มีหน้าวิกิพีเดียของตัวเอง ถ้าลอง inspect ดีๆจะพบว่า link เหล่านั้น จะมี `class=\"new\"` กำกับไว้ \n",
    "\n",
    "<img src=\"source/class_new.png\">\n",
    "\n",
    "ถ้าเราอยากได้รายชื่อผู้กำกับที่ยังไม่มีหน้าวิกิของตัวเอง เราก็สามารถทำได้โดยการดึกข้อมูลจาก link `<a>` ที่มี attribute `class` เท่ากับ `new`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "qFLm8Cxkw7CC"
   },
   "outputs": [],
   "source": [
    "for a in director_list.find_all('a', {\"class\": \"new\"}):  # Or director_list.find_all('a', class_ ='new')\n",
    "    print(a.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EKwaU0pOw7CI"
   },
   "source": [
    "## นักแสดงนาดาวบางกอก\n",
    "\n",
    "ได้เวลาทดสอบความสามารถกันแล้ว! ลองเขียนโค้ดเพื่อดึงรายชื่อนักแสดงในสังกัดนาดาวบางกอก จากวิกิพีเดียกันดู\n",
    "\n",
    "<img src=\"source/nadao_artists.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "n83-_rW2w7CJ"
   },
   "outputs": [],
   "source": [
    "# Assignment in class\n",
    "artists_list = soup.find('b', string='นาดาวบางกอก').find_next('ul')\n",
    "for li in artists_list('li'):\n",
    "    print(li.a.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3rfLOn1Ew7CN"
   },
   "source": [
    "## ผลงานภาพยนตร์ของ GDH\n",
    "\n",
    "ในแบบฝึกหัดต่อไป เราจะมาทำการดึงข้อมูลภาพยนตร์ของ GDH จากหน้าวิกิพีเดียกัน ว่าหนังแต่ละเรื่องเข้าฉายเมื่อไหร่ ทำรายได้ไปมากน้อยแค่ไหน และใครเป็นผู้กำกับ\n",
    "\n",
    "<img src=\"source/product.png\">\n",
    "\n",
    "เช่นเคย เรามาเริ่มต้นจากการหา `<table>` ที่เราต้องการกันก่อน"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = soup.find(string='ภาพยนตร์').find_next('table').find_next('table')\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8drKjueNw7CT"
   },
   "source": [
    "ปัญหาอย่างหนึ่งของตารางนี้ คือการใช้คำสั่ง `rowspan` ทำให้แต่ละแถว `<tr>` ในตาราง อาจะมีจำนวนคอลัมน์ `<td>` ไม่เท่ากัน ส่งผลให้ชื่อหนัง อาจจะอยู่ในคอลัมน์ที่ 0 หรือ 1 ก็ได้ ขึ้นอยู่กับว่าแถวนั้นเป็นแถวแรกของปีนั้นๆหรือไม่ \n",
    "\n",
    "<img src=\"source/rowspan.png\">\n",
    "\n",
    "เพื่อความง่าย เราจะไม่สนใจปีที่หนังเข้าฉายกันไปก่อน และลบ `<td>` ทุกอันที่มีการระบุค่า `rowspan` ด้วยฟังก์ชัน `extract()` เนื่องจากเดี๋ยวเราจะกลับมาใช้ตารางเต็มๆกันอีกครั้ง เราจึงต้องสร้างอีก copy `table` ไว้ก่อน \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "v9LORAb6w7CU"
   },
   "outputs": [],
   "source": [
    "# print(table('tr'))\n",
    "# print(table.find_all('td', {'rowspan': True}))\n",
    "\n",
    "simplified_table = copy.copy(table) # จะเกิดอะไรขึ้นถ้าเราใช้ `simplified_table = table` ? \n",
    "for td in simplified_table('td', {'rowspan': True}):\n",
    "    td.extract() # ลบ element จาก DOM tree\n",
    "\n",
    "print(urllib.parse.unquote(str(simplified_table)))\n",
    "# print(table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v3E7Uq7bw7Cb"
   },
   "source": [
    "จะเห็นได้ว่า ตอนนี้ทุกแถวมี `<td>` สามอัน เท่ากันหมดแล้ว ทีนี้เราก็สามารถดึงข้อมูลออกมาได้ง่ายๆตามนี้"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "IvU1U2w_w7Cc"
   },
   "outputs": [],
   "source": [
    "for tr in simplified_table('tr'):\n",
    "    cells = tr('td')\n",
    "    if len(cells):  # ทำไมต้องมีบรรทัดนี้ ?\n",
    "        print('\"%s\", \"%s\", \"%s\"' % (cells[0].text, cells[1].text, cells[2].text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vteDWVZFw7Ch"
   },
   "source": [
    "เราจะกำจัดแหล่งข้อมูลอ้างอิง เช่น `[12],[13],[14]` ออกจากชุดข้อมูลเราได้อย่างไร\n",
    "\n",
    "**HINT:** \n",
    "- ลอง inspect ดูว่า element เหล่านั้น มี attribute อะไรเป็นพิเศษ\n",
    "- และเราจะสามารถลบ element นั้นก่อนที่จะประมวลผลตารางได้อย่างไร"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "Z-QfPzZww7Ci"
   },
   "outputs": [],
   "source": [
    "# ----- TO DO 2 -----\n",
    "# QUIZ(1%) จงลบแหล่งข้อมูลอ้างอิง เช่น [12],[13],[14] ออกจากข้อมูล \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tyuzG3sxw7Cp"
   },
   "source": [
    "สำหรับคนที่อยากรู้ว่า ถ้าจะเอาข้อมูลปีที่เข้าฉายมาใช้ด้วย เราจะทำได้อย่างไร ลองพยายามทำความเข้าใจโค้ดข้างล่างนี้ดู"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "HiByo5WQw7Cq"
   },
   "outputs": [],
   "source": [
    "for sup in table('sup'):\n",
    "    sup.extract()\n",
    "\n",
    "rows = table('tr')\n",
    "header = rows[0]\n",
    "n_cols = len(header('th'))\n",
    "\n",
    "current_year = None\n",
    "movies = []\n",
    "\n",
    "for tr in rows[1:]:\n",
    "    movie = {}\n",
    "    cells = tr('td')\n",
    "    if cells[0].has_attr('rowspan'):\n",
    "        current_year = tr.td.text\n",
    "        cells = cells[1:]\n",
    "\n",
    "    movie['year'] = current_year\n",
    "    movie['name'] = cells[0].text\n",
    "    movie['release_date'] = '%s %s' % (cells[1].text, current_year)\n",
    "    movie['gross'] = cells[2].text\n",
    "    movie['url'] = cells[0].a['href']\n",
    "    movies.append(movie)\n",
    "\n",
    "# TO DO 3 : เปลี่ยน url format % ให้อยู่ในรูปแบบ utf-8 (ต้องการแสดงผล url ที่เป็นภาษาไทย)\n",
    "# ตัวอย่าง :เปลี่ยนจาก '/wiki/%E0%B9%81%E0%B8%9F%E0%B8%99%E0%B9%80%E0%B8%94%E0%B8%A2%E0%B9%8C' ให้เป็น '/wiki/แฟนเดย์..แฟนกันแค่วันเดียว'\n",
    "\n",
    "\n",
    "print(movies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G8OOPbTmw7Cs"
   },
   "source": [
    "ถึงตอนนี้ทุกคนอาจจะสงสัยว่า ทำไมเราต้องเขียนโค้ดให้มันวุ่นวายขนาดนี้ แค่ copy/paste แป๊ปเดียวก็เสร็จแล้ว\n",
    "\n",
    "ถูกต้อง! และ Data scientist ที่ดีก็ควรจะเลือกใช้วิธีที่ช่วยให้เราทำงานได้เร็วที่สุด \n",
    "\n",
    "แต่...ตัวอย่างข้างต้นนั้น เป็นเพียงตัวอย่างง่ายๆเท่านั้น ในตัวอย่างถัดไป เราจะมาดึงข้อมูลว่าหนังแต่ละเรื่องใครกำกับ ซึ่งข้อมูลนี้ไม่ได้ให้มาในตาราง แต่เราสามารถหาได้ในหน้าวิกิของหนังแต่ละเรื่อง "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# โค๊ดเหมือนเดิม เราเอากลับมาเป็น % เหมือนเดิมเพราะภาษาไทยใช้ในการแสดงผลเท่านั้น\n",
    "# ไม่สามารถนำ url ที่มีภาษาไทยต่อท้ายมา crawl data ได้\n",
    "\n",
    "movies = []\n",
    "\n",
    "for tr in rows[1:]:\n",
    "    movie = {}\n",
    "    cells = tr('td')\n",
    "    if cells[0].has_attr('rowspan'):\n",
    "        current_year = tr.td.text\n",
    "        cells = cells[1:]\n",
    "\n",
    "    movie['year'] = current_year\n",
    "    movie['name'] = cells[0].text\n",
    "    movie['release_date'] = '%s %s' % (cells[1].text, current_year)\n",
    "    movie['gross'] = cells[2].text\n",
    "    movie['url'] = cells[0].a['href']\n",
    "    movies.append(movie)\n",
    "    \n",
    "print(movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "9CdEU2ksw7Ct"
   },
   "outputs": [],
   "source": [
    "for movie in movies:\n",
    "    print('Processing ' + movie['name'] + '...')\n",
    "    \n",
    "    if movie['name'] == 'K1189B54N' or movie['name'] == 'Friend Zone':\n",
    "        movie['directors'] = [u'ไม่ทราบรายชื่อผู้กำกับ']\n",
    "        continue\n",
    "        \n",
    "    movie_html = urllib.request.urlopen('http://th.wikipedia.com' + movie['url'])\n",
    "    movie_soup = BeautifulSoup(movie_html, 'html.parser')\n",
    "    direct_td = movie_soup.find('th', text='กำกับ').find_next()\n",
    "    movie['directors'] = [x.text for x in direct_td('a')] # list comprehension\n",
    "    \n",
    "    # มารยาทในการดึงข้อมูลเราควรที่จะต้องใส่ sleep เพื่อไม่ให้ server ทำงานหนักเกินไป\n",
    "    sleep(1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "STAijwFew7Cw"
   },
   "outputs": [],
   "source": [
    "for m in movies:\n",
    "    print('\"%s\", \"%s\", \"%s\", \"%s\"' % \n",
    "          (m['name'], m['release_date'], m['gross'], m['directors']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "text",
    "id": "5OptC8Rsw7Cz"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "01-web-scraping.ipynb",
   "private_outputs": true,
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
